---
title: "Midterm Source Code"
author: "Shiva Neelakantan"
sid: 616916317
date: '2022-02-28'
output: html_document
---

**I certify that all work on this exam is my own original work and have upheld ISUâ€™s policy on academic dishonesty.**

# QUESTION 2

## note: Problems 1, 2a, and 2b are in the other document.

## 2c
```{r}
input = data.frame(X1=2, X2=1)
X1 = seq(0, 10, length.out=100)
X2 = runif(100, 0, 2)
error = rnorm(100, 0, 1)
Y = 2 + 3 * X1 + 4 * X2 + error
df = data.frame(X1, X2, Y)
model = lm(Y~., df)
print(predict.lm(model, input))
```

## 2d
```{r}
preds = c()
for (i in seq(100)) {
  input = data.frame(X1=2, X2=1)
  X1 = seq(0, 10, length.out=100)
  X2 = runif(100, 0, 2)
  error = rnorm(100, 0, 1)
  Y = 2 + 3 * X1 + 4 * X2 + error
  df = data.frame(X1, X2, Y)
  model = lm(Y~., df)
  preds = append(preds, predict(model, input))
}
mean(preds)
```

## 2e
```{r}
library(ggplot2)
ggplot(NULL, aes(x=preds)) + geom_histogram(color='white', fill='steelblue') + geom_vline(aes(xintercept=(2+3*2+4*1)), color='red')
```
## 2f
```{r}
input = data.frame(X1=2, X2=1)
X1 = seq(0, 10, length.out=100)
X2 = runif(100, 0, 2)
error = rnorm(100, 0, 1)
Y = 2 + 3 * X1 + 4 * X2 + error
df = data.frame(X1, X2, Y)
model = lm(Y~., df)
simtest = predict(model, input, interval='confidence', level=0.95)
simtest
```

We can say with 95% confidence that the true value of Y will fall within the lower and upper bounds of the interval printed above.


# QUESTION 3

## 3a
```{r}
library(ISLR2)
model.grad = lm(Grad.Rate~., College)
summary(model.grad)
```
*H0*: All the predictors are 0
*H1*: At least one of the predictors is not 0

*F-statistic (from R output)*: 38.27

*Null distribution*: When e ~ N(0, sigma ** 2) and we assume H0, F* has a null distribution of F_(17, 743).

*p-value (from R output)*: 2.2e-16

*Conclusion*: Assume a significance level alpha of 0.01. Because our p-value is much lower than alpha, we reject the null hypothesis. Alternatively stated, we have enough statistical evidence that at least one of the predictors in our dataset is linearly correlated to Graduation Rate.

## 3b
```{r}
model.private = lm(Grad.Rate~Private, College)
summary(model.private)
```

*H0*: The private predictor is 0
*H1*: The private predictor is not 0

*t-statistic (from R output)*: 98.74

*Null distribution*: When e ~ N(0, sigma ** 2) and we assume H0, F* has a null distribution of F_(1, 775).

*p-value (from R output)*: 2.2e-16

*Conclusion*: Assume a significance level alpha of 0.01. Because our p-value is much lower than alpha, we reject the null hypothesis. Alternatively stated, we have enough statistical evidence that there is a roughly linear relationship between graduation rate and attending a private university.

## 3c
The regression coefficient of **Private** indicates a positive correlation between graduation rate and whether one attends a private university, when holding all other predictors constant. This conclusion makes sense, as generally speaking, private schools tend to be known for their high graduation and placement rates.

## 3d
```{r}
varYi = mean((model.private$residuals)^2)
varYi
```

## 3e
When multicollinearity is present, our F-test results will be affected; it will have a higher chance of seeing significant results. In other words, we will be more likely to believe one of the predictors is significant. This leads into another issue with F-tests, which is that we do not know which specific predictors are statistically significant compared to the others. 