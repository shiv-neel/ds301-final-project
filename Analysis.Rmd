---
title: "CBB_Analysis"
author: "Shiva Neelakantan, Ryan Scehovic, Ryan McNally, Saketh Jonnadula"
date: '2022-05-01'
output: html_document
---

```{r}
df = read.csv('./cbb.csv')
df[is.na(df)] <- -1
sum(is.na(df))
df$teamYear = paste(df$TEAM, df$YEAR)
head(df)
```

```{r}
library(leaps)
library(ggplot2)
library(VIM)
library(cluster)
library(dplyr)
library(ROCR)
library(MASS)
```

```{r}
df = df %>% mutate(WinRate = W/G)
for (i in 1:length(df$POSTSEASON)) {
  if (df$POSTSEASON[i] == 'Champions')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == '2ND')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'F4')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'E8')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'S16')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'R32')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'R64')
    df$POSTSEASON[i] = 1
  else df$POSTSEASON[i] = 0
}
df$SEED[is.na(df$SEED)] = 0
```

creating training and test sets
```{r}
set.seed(7)
trainIdx = sample(1:nrow(df),nrow(df)/2, replace=FALSE)
train = df[trainIdx,]
test = df[-trainIdx,]

```


```{r}
head(df)
hist(df$G, main="Number of games played")
hist(df$W, main="Number of games won")
hist(df$ADJOE, main="Adjusted Offensive Efficiency ")
hist(df$ADJDE, main="Adjusted Defensive Efficiency")
hist(df$BARTHAG, main="Power Rating")
hist(df$EFG_O, main="Effective Field Goal Percentage Shot")
hist(df$EFG_D, main="Effective Field Goal Percentage Allowed")
hist(df$TOR, main="Turnover Percentage Allowed (Turnover Rate)")
hist(df$TORD, main="Turnover Percentage Committed (Steal Rate)")
hist(df$ORB, main="Offensive Rebound Rate")
hist(df$DRB, main="Offensive Rebound Rate Allowed")
hist(df$FTR, main="Free Throw Rate")
hist(df$FTRD, main="Free Throw Rate Allowed")
hist(df$X2P_O, main="Two-Point Shooting Percentage")
hist(df$X2P_D, main="Two-Point Shooting Percentage Allowed")
hist(df$X3P_O, main="Three-Point Shooting Percentage")
hist(df$X3P_D, main="Three-Point Shooting Percentage Allowed")
hist(df$ADJ_T, main="Adjusted Tempo")
hist(df$WAB, main="Wins Above Bubble")
hist(df$SEED, main="Tournament Seed")
hist(df$WinRate, main="Win Rate")
```

# Q1 SETUP
```{r}
set.seed(7)
df2 <- df[5:22]
df2$WinRate=df$WinRate
df2$POSTSEASON=as.numeric(df2$POSTSEASON)
df2$SEED=df$SEED
train_index = sample(1:nrow(df2),nrow(df2)/4, replace=FALSE)
test_index = -train_index
train = df2[train_index,]
test = df2[-train_index,]
```

#Q1 logistic regression assumption test
```{r}
cor(df2[,c('ADJOE', #'EFG_O',
            'TOR',  'ORB', 
            'FTR', 'X2P_O', 'X3P_O', 'ADJ_T')])


cor(df2[,c('ADJDE','TORD','DRB', 'FTRD','X2P_D','X3P_D')])
#'EFG_D',
```


# Q1 logistic regression - offense + defense
```{r}
library(MASS)
glm.fit = glm(POSTSEASON~ADJOE+ADJDE+TOR+TORD+ORB+DRB+FTR+FTRD+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T, data=df2, subset=train_index, family='binomial')
summary(glm.fit)
glm.prob = predict(glm.fit, test,type='response') 
glm.pred = rep(0,nrow(test))
glm.pred[glm.prob >0.5] = 1
table(glm.pred,test$POSTSEASON)
1-mean(glm.pred == test$POSTSEASON)
cMatrix=table(glm.pred,test$POSTSEASON)
falsenegRate = cMatrix[1,2] / nrow(test)
falsenegRate
falseposRate = cMatrix[2,1] / nrow(test)
falseposRate
ROCRpred <- prediction(glm.prob,test$POSTSEASON)
plot(performance(ROCRpred,'tpr','fpr'))
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
     print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
```

# Q1 logistic regression - offense only
```{r}
#ADJOE+ADJDE+EFG_O+EFG_D+TOR+TORD+ORB+DRB+FTR+FTRD+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T
glm.fit = glm(POSTSEASON~ADJOE+TOR+ORB+FTR+X2P_O+X3P_O+ADJ_T, data=df2, subset=train_index, family='binomial')
summary(glm.fit)
glm.prob = predict(glm.fit, test,type='response') 
glm.pred = rep(0,nrow(test))
glm.pred[glm.prob >0.5] = 1
table(glm.pred,test$POSTSEASON) #rows are predicted, # columns are true 
1-mean(glm.pred == test$POSTSEASON)
cMatrix=table(glm.pred,test$POSTSEASON)
falsenegRate = cMatrix[1,2] / nrow(test)
falsenegRate
falseposRate = cMatrix[2,1] / nrow(test)
falseposRate
ROCRpred <- prediction(glm.prob,test$POSTSEASON)
plot(performance(ROCRpred,'tpr','fpr'))
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
     print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
```

# Q1 logistic regression - defense only
```{r}
#ADJOE+ADJDE+EFG_O+EFG_D+TOR+TORD+ORB+DRB+FTR+FTRD+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T
glm.fit = glm(POSTSEASON~ADJDE+TORD+DRB+FTRD+X2P_D+X3P_D, data=df2, subset=train_index, family='binomial')
summary(glm.fit)
glm.prob = predict(glm.fit, test,type='response') 
glm.pred = rep(0,nrow(test))
glm.pred[glm.prob >0.5] = 1
table(glm.pred,test$POSTSEASON)
1-mean(glm.pred == test$POSTSEASON)
cMatrix=table(glm.pred,test$POSTSEASON)
falsenegRate = cMatrix[1,2] / nrow(test)
falsenegRate
falseposRate = cMatrix[2,1] / nrow(test)
falseposRate
ROCRpred <- prediction(glm.prob,test$POSTSEASON)
plot(performance(ROCRpred,'tpr','fpr'))
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
     print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
```

# Q1 - Testing for LDA Assumptions
```{r}
#ADJOE+ADJDE+EFG_O+EFG_D+TOR+TORD+ORB+DRB+FTR+FTRD+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T

CovMatrix <- cbind(df2$ADJOE, df2$ADJDE, df2$EFG_O, df2$EFG_D, df2$TOR, df2$TORD, df2$ORB, df2$DRB, df2$FTR, df2$FTRD,
                   df2$X2P_O, df2$X2P_D, df2$X3P_O, df2$X3P_D, df2$ADJ_T)
cov(CovMatrix)
```



# Q1 LDA - offense + defense
```{r}
lda.fit = lda(POSTSEASON~ADJOE+ADJDE+EFG_O+EFG_D+TOR+TORD+ORB+DRB+FTR+FTRD+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T, data=df2, subset=train_index)
summary(lda.fit)
lda.pred = predict(lda.fit,test)
table(lda.pred$class,test$POSTSEASON)
mean(lda.pred$class==test$POSTSEASON)
```


# Q1 LDA - offense only
```{r}
lda.fit = lda(POSTSEASON~ADJOE+EFG_O+TOR+ORB+FTR+X2P_O+X3P_O+ADJ_T, data=df2, subset=train_index)
summary(lda.fit)
lda.pred = predict(lda.fit,test)
table(lda.pred$class,test$POSTSEASON)
mean(lda.pred$class==test$POSTSEASON)
```


# Q1 LDA - defense only
```{r}
lda.fit = lda(POSTSEASON~ADJDE+EFG_D+TORD+DRB+FTRD+X2P_D+X3P_D, data=df2, subset=train_index)
summary(lda.fit)
lda.pred = predict(lda.fit,test)
table(lda.pred$class,test$POSTSEASON)
mean(lda.pred$class==test$POSTSEASON)
```



# Q2 Subset Selection
```{r}
forward = regsubsets(WinRate~ADJOE+ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T, data=df, nvmax=24, method='forward')
forward.summary = summary(forward)
forward.summary
n = dim(df)[1]
p = rowSums(forward.summary$which)
forward.rss = forward.summary$rss
forward.aic = n * log(forward.rss/n) + 2*p
forward.bic = n * log(forward.rss/n) + p*log(n)
plot(forward.rss)
plot(forward.bic)
min(forward.rss)
forward.aic
min(forward.bic)
forward.bic
```

```{r}
backward = regsubsets(WinRate~ADJOE+ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T, data=df, nvmax=24, method='backward')
backward.summary = summary(backward)
backward.summary
n = dim(df)[1]
p = rowSums(backward.summary$which)
backward.rss = backward.summary$rss
backward.aic = n * log(backward.rss/n) + 2*p
backward.bic = n * log(backward.rss/n) + p*log(n)
plot(backward.rss)
plot(backward.bic)
min(backward.rss)
backward.aic
min(backward.bic)
backward.bic
```

## Q2 -- MLR
* NEED TO ADD CV*
```{r}
mlr.model = lm(WinRate~ADJOE+ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T,data=train)

model.summary = summary(mlr.model)
mean((test$WinRate - predict.lm(mlr.model, test)) ^ 2)
```

```{r}
library(caret)
library(class)

df3 = df
head(df3)
standardized.X2 = scale(df3[,-26])  # -26 if full df, if you make it train then -19

flds <- createFolds(df3$WinRate, k = 5, list = TRUE, returnTrain = FALSE)
names(flds)

K= c(1,3,5) # nearest neighbor values

cv_error = matrix(NA, 5, 3)

for(j in 1:3){
  k = K[j]
  for(i in 1:5){
    test_index = flds[[i]]
    testX = standardized.X2[test_index,]
    trainX = standardized.X2[-test_index,]
    
    trainY = df3$WinRate[-test_index]
    testY = df3$WinRate[test_index]
    
    knn.pred = knn(trainX,testX,trainY,k=k)
    cv_error[i,j] = mean(testY!=knn.pred)
  }
}

train.X = standardized.X2[train_index,]
test.X = standardized.X2[test_index,]
train.Y = df3$WinRate[train_index]
test.Y = df3$WinRate[test_index]

apply(cv_error,2,mean)

knn.pred = knn(train.X,test.X,train.Y,k=5)
mean(test.Y!=knn.pred)
```

```{r}
library(glmnet)
x = model.matrix(WinRate~ADJOE+ADJDE+EFG_O+EFG_D+TOR+TORD+ORB+DRB+FTR+FTRD+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T,data=df)[,-1] 
Y = train$WinRate
grid = 10^seq(10,-2,length=100)
cv.out.ridge = cv.glmnet(x[trainIdx,],Y,alpha = 0, lambda = grid) 
plot(cv.out.ridge)
bestlambda = cv.out.ridge$lambda.min
bestlambda
#really small lambda means a very flexible model.
ridge.train = glmnet(x[trainIdx,],Y,alpha=0,lambda=grid)
ridge.pred = predict(ridge.train,s=bestlambda,newx=x[-trainIdx,])
mean((ridge.pred-Y[-trainIdx])^2)
final.ridge = glmnet(x[trainIdx,],Y,alpha=0,lambda=bestlambda)
coef(final.ridge)

plot(ridge.train,xvar="lambda",label=TRUE)
```


# Q2 ridge
```{r}
library(glmnet)
x = model.matrix(WinRate~ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T,data=df2)[,-1] 
Z = df[trainIdx,]$WinRate
grid = 10^seq(10,-2,length=100)
cv.out.ridge = cv.glmnet(x[trainIdx,],Z,alpha = 0, lambda = grid) 
plot(cv.out.ridge)
bestlambda = cv.out.ridge$lambda.min
bestlambda
#really small lambda means a very flexible model.
ridge.train = glmnet(x[trainIdx,],Z,alpha=0,lambda=grid)
ridge.pred = predict(ridge.train,s=bestlambda,newx=x[-trainIdx,])
mean((ridge.pred-Z[-trainIdx])^2)
final.ridge = glmnet(x[trainIdx,],Z,alpha=0,lambda=bestlambda)
coef(final.ridge)

plot(ridge.train,xvar="lambda",label=TRUE)
```
#Lasso
```{r}
library(glmnet)
x = model.matrix(WinRate~ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T,data=df2)[,-1] 
Z = df[trainIdx,]$WinRate
grid = 10^seq(10,-2,length=100)
cv.out.lasso = cv.glmnet(x[trainIdx,],Z,alpha = 1, lambda = grid) 
plot(cv.out.lasso)
bestlambda2 = cv.out.lasso$lambda.min
bestlambda2
#really small lambda means a very flexible model.
lasso.train = glmnet(x[trainIdx,],Z,alpha=1,lambda=grid)
lasso.pred = predict(lasso.train, s=bestlambda2,newx=x[-trainIdx,])
mean((lasso.pred-Z[-trainIdx])^2)
final.lasso = glmnet(x[trainIdx,],Z,alpha=1,lambda=bestlambda2)
coef(final.lasso)

plot(lasso.train,xvar="lambda",label=TRUE)
```
