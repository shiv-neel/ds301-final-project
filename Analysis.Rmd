---
title: "CBB_Analysis"
author: "Shiva Neelakantan"
date: '2022-05-01'
output: html_document
---

```{r}
df = read.csv('./cbb.csv')
df[is.na(df)] <- -1
sum(is.na(df))
df$teamYear = paste(df$TEAM, df$YEAR)
head(df)
```

```{r}
library(leaps)
library(ggplot2)
library(VIM)
library(cluster)
library(dplyr)
```

```{r}
df = df %>% mutate(WinRate = W/G)
for (i in 1:length(df$POSTSEASON)) {
  if (df$POSTSEASON[i] == 'Champions')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == '2ND')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'F4')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'E8')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'S16')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'R32')
    df$POSTSEASON[i] = 1
  else if (df$POSTSEASON[i] == 'R64')
    df$POSTSEASON[i] = 1
  else df$POSTSEASON[i] = 0
}
df$SEED[is.na(df$SEED)] = 0
```

creating training and test sets
```{r}
set.seed(7)
trainIdx = sample(1:nrow(df),nrow(df)/2, replace=FALSE)
train = df[trainIdx,]
test = df[-trainIdx,]

```
```{r}
head(df)

hist(df$G)
hist(df$W)
hist(df$ADJOE)
hist(df$ADJDE)
hist(df$BARTHAG)
hist(df$EFG_O)
hist(df$EFG_D)
hist(df$TOR)
hist(df$TORD)
hist(df$ORB)
hist(df$DRB)
hist(df$FTR)
hist(df$FTRD)
hist(df$X2P_O)
hist(df$X2P_D)
hist(df$X3P_O)
hist(df$X3P_D)
hist(df$ADJ_T)
hist(df$WAB)
```

# Q1 logistic regression
```{r}
library(MASS)
set.seed(7)

df2 <- df[5:22]
df2$WinRate=df$WinRate
df2$POSTSEASON=as.numeric(df2$POSTSEASON)
df2$SEED=df$SEED

train_index = sample(1:nrow(df2),nrow(df2)/4, replace=FALSE)
test_index = -train_index
train = df2[train_index,]
test = df2[-train_index,]

#got these from subset regression RSS
glm.fit = glm(POSTSEASON~BARTHAG+ADJOE+ADJDE+EFG_O+EFG_D+TOR+TORD+ORB+DRB+FTR+X3P_D+ADJ_T, data=df2, subset=train_index, family='binomial')
summary(glm.fit)

#glm.fit2 = glm(POSTSEASON~BARTHAG+ADJOE+ADJDE+TOR+FTR, data=df2, subset=train_index, family='binomial')
#summary(glm.fit2)
```

```{r}
glm.prob = predict(glm.fit, test,type='response') 
glm.pred = rep(0,nrow(test))

#glm.pred
glm.pred[glm.prob >0.5] = 1

table(glm.pred,test$POSTSEASON) #rows are predicted, # columns are true 
# This matrix is called our confusion matrix

#test
#test$POSTSEASON
#glm.pred

# what is our misclassification rate? 
1-mean(glm.pred == test$POSTSEASON)
```

# Q1 QDA
```{r}
qda.fit = qda(POSTSEASON~BARTHAG+ADJOE+ADJDE+TOR+FTR, data=df2, subset=train_index)
summary(qda.fit)

qda.pred = predict(qda.fit,test)
table(qda.pred$class,test$POSTSEASON)

mean(qda.pred$class==test$POSTSEASON)
```

# Q2 Subset Selection
```{r}
forward = regsubsets(WinRate~ADJOE+ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T, data=df, nvmax=24, method='forward')
forward.summary = summary(forward)
forward.summary
n = dim(df)[1]
p = rowSums(forward.summary$which)
forward.rss = forward.summary$rss
forward.aic = n * log(forward.rss/n) + 2*p
forward.bic = n * log(forward.rss/n) + p*log(n)
plot(forward.rss)
plot(forward.bic)
min(forward.rss)
forward.aic
min(forward.bic)
forward.bic
```

```{r}
backward = regsubsets(WinRate~ADJOE+ADJDE+TOR+TORD+ORB+DRB+FTR+X2P_O+X2P_D+X3P_O+X3P_D+ADJ_T, data=df, nvmax=24, method='backward')
backward.summary = summary(backward)
backward.summary
n = dim(df)[1]
p = rowSums(backward.summary$which)
backward.rss = backward.summary$rss
backward.aic = n * log(backward.rss/n) + 2*p
backward.bic = n * log(backward.rss/n) + p*log(n)
plot(backward.rss)
plot(backward.bic)
min(backward.rss)
backward.aic
min(backward.bic)
backward.bic
```
